{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the API key for ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "api = str(dotenv_values(\".env\")['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=api, model=gpt-4-vision-preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Para utilizar Langchain para leer y analizar el contenido del archivo en el código proporcionado, puedes seguir los siguientes pasos:\\n\\n1. Importa el módulo de Langchain en tu código:\\n\\n```python\\nimport langchain\\n```\\n\\n2. Después de la línea `files_tuple = [(\"file\", (f.name, f)) for f in files]`, puedes añadir el siguiente código para leer el contenido del archivo utilizando Langchain:\\n\\n```python\\ncontents = []\\nfor file in files:\\n    # Leer el contenido del archivo utilizando Langchain\\n    with open(file, \\'r\\') as f:\\n        content = f.read()\\n        contents.append(content)\\n```\\n\\n3. Ahora puedes utilizar Langchain para analizar el contenido del archivo. Por ejemplo, puedes utilizar la función `langchain.analyze_sentiment()` para analizar el sentimiento del contenido:\\n\\n```python\\nfor content in contents:\\n    # Analizar el sentimiento del contenido utilizando Langchain\\n    sentiment = langchain.analyze_sentiment(content)\\n    print(sentiment)\\n```\\n\\nRecuerda que necesitarás tener instalado Langchain y sus dependencias para poder utilizarlo en tu código. Además, asegúrate de que los archivos que estás procesando sean archivos de texto legibles.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = llm.invoke(\"\"\"\n",
    "    'En base al siguiente código que es el que procesa un archivo \"def send_files(files):\n",
    "    # api where the files should be sent\n",
    "    api = \"http://localhost:8000/api/upload-file/\"\n",
    "    # create a tuple for each file. It can be used list comprehension or append method.\n",
    "    files_tuple = [(\"file\", (f.name, f)) for f in files]\n",
    "    print(files_tuple)\n",
    "    # post request\n",
    "    response = requests.post(api, files=files_tuple)\n",
    "    \n",
    "    # verify the answer\n",
    "    if response.status_code == 201:\n",
    "        st.success(\"Files sucessfully sent to the server.\")\n",
    "    else:\n",
    "        st.error(f\"Error! Messages have not been processed. {response.status_code} - {response.text}\")\", \n",
    "    ¿cómo puedo utilizar Langchain para leer y analizar el contenido del archivo?\n",
    "    \"\"\")\n",
    "output.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp-YVMtmPuC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
